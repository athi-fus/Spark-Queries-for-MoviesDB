{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd9452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|Before the Fall (...|\n",
      "|   Dancemaker (1998)|\n",
      "|Fear Strikes Out ...|\n",
      "|Gate of Heavenly ...|\n",
      "|Life Is Rosy (a.k...|\n",
      "|Married to It (1991)|\n",
      "|My Life and Times...|\n",
      "|Not Love, Just Fr...|\n",
      "|Paris Was a Woman...|\n",
      "|Take Care of My C...|\n",
      "+--------------------+\n",
      "\n",
      "\n",
      "Scheduling mode = FIFO\n",
      "Spark Context default degree of parallelism = 2\n",
      "Aggregated Spark stage metrics:\n",
      "numStages => 12\n",
      "numTasks => 416\n",
      "elapsedTime => 59941 (60 s)\n",
      "stageDuration => 53499 (53 s)\n",
      "executorRunTime => 89857 (1.5 min)\n",
      "executorCpuTime => 63721 (1.1 min)\n",
      "executorDeserializeTime => 4277 (4 s)\n",
      "executorDeserializeCpuTime => 3201 (3 s)\n",
      "resultSerializationTime => 52 (52 ms)\n",
      "jvmGCTime => 2780 (3 s)\n",
      "shuffleFetchWaitTime => 0 (0 ms)\n",
      "shuffleWriteTime => 1091 (1 s)\n",
      "resultSize => 969815 (947.0 KB)\n",
      "diskBytesSpilled => 0 (0 Bytes)\n",
      "memoryBytesSpilled => 0 (0 Bytes)\n",
      "peakExecutionMemory => 1447131200\n",
      "recordsRead => 40055086\n",
      "bytesRead => 1384480482 (1320.0 MB)\n",
      "recordsWritten => 0\n",
      "bytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsRead => 50553\n",
      "shuffleTotalBlocksFetched => 1400\n",
      "shuffleLocalBlocksFetched => 1400\n",
      "shuffleRemoteBlocksFetched => 0\n",
      "shuffleTotalBytesRead => 1104170 (1078.0 KB)\n",
      "shuffleLocalBytesRead => 1104170 (1078.0 KB)\n",
      "shuffleRemoteBytesRead => 0 (0 Bytes)\n",
      "shuffleRemoteBytesReadToDisk => 0 (0 Bytes)\n",
      "shuffleBytesWritten => 1104170 (1078.0 KB)\n",
      "shuffleRecordsWritten => 50553\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from sparkmeasure import StageMetrics\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "spark = SparkSession.builder.appName('q4').config(\"spark.jars\", \"/home/athina/Downloads/spark-measure_2.12-0.17.jar\").getOrCreate()\n",
    "#For VIRTUAL\n",
    "#spark = SparkSession.builder.master('spark://picachu-VirtualBox:7077').appName('q4').config(\"spark.jars\", \"/home/athina/Downloads/spark-measure_2.12-0.17.jar\").getOrCreate()\n",
    "\n",
    "#For LIVY\n",
    "#spark=SparkSession.builder.master('spark://localhost:7077').appName(\"Testing\").getOrCreate()\n",
    "#and changed the filepaths to '/home/administrator/Downloads/movielens/file_name.csv'\n",
    "\n",
    "stagemetrics = StageMetrics(spark)\n",
    "stagemetrics.begin()#start measuring performance\n",
    "\n",
    "df_rating= (spark.read\n",
    "     .format(\"csv\")\n",
    "     .option('header', 'true')\n",
    "     .option('delimiter', \",\")\n",
    "     .option(\"inferSchema\",\"true\")\n",
    "     .load(\"rating.csv\") \n",
    "    )\n",
    "\n",
    "# get the year and adds it to a new column # Columns: userId, rating and year\n",
    "withyear=df_rating.select('movieId','rating',regexp_extract('timestamp', r'\\d{4}', 0).cast(IntegerType()).alias('year'))\n",
    "\n",
    "#calculating the average for each movieId and its rating year\n",
    "average=withyear.groupBy('movieId','year').avg('rating').select('movieId','year',col('avg(rating)').alias('avg_rating')).orderBy('year')\n",
    "\n",
    "df_movie= (spark.read\n",
    "     .format(\"csv\")\n",
    "     .option('header', 'true')\n",
    "     .option('delimiter', \",\")\n",
    "     .option(\"inferSchema\",\"true\")\n",
    "     .load(\"movie.csv\") \n",
    "    )\n",
    "#combining movieId with movie's title\n",
    "average_titles=average.join(df_movie, df_movie['movieId']==average['movieId'],\"inner\").hint(\"broadcast\").select(average['movieId'],'title','year','avg_rating')\n",
    "\n",
    "#Taking the first 10 movies with the most rating average \n",
    "#If more have the same top average then take them with alphabetical order\n",
    "windowSpec=Window.partitionBy(average_titles['year']).orderBy(average_titles['avg_rating'].desc(),average_titles['title'].asc())\n",
    "tops=average_titles.withColumn('row',row_number().over(windowSpec))\n",
    "\n",
    "#keeping only the top 10 movies of each year\n",
    "results=tops.filter(tops['row'] <=10).select('movieId','title','year','avg_rating')\n",
    "results.select('title').filter(tops['year']==2005).show()#requested answer for query 4\n",
    "\n",
    "stagemetrics.end()#stop measuring performance\n",
    "stagemetrics.print_report()#print performance metrics\n",
    "spark.stop() # stop spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc0acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50954e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
